# -*- coding: utf-8 -*-
"""svm_dec_tree_rand_frst.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zSLYEMTtZkx2g0yUMhREVI54jy-J0VYf

# Intoduction to SVM
Use SVM to build and train a model using human cell records, and classify cells to whether the samples are benign(mild state) or malignant (evil state)

SVM works by mapping data to a high- dimensional feature space so that data points can  be categorised even ehen the data are not otherwise linearly separable(This gets done by kernel function of SVM classifier). A separator between categories is found , then the data is transformedin such a way that the separatoe could be drawn as a hyperplane.
"""

# Import necessary libraries
import pandas as pd
import numpy as np
#import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

"""# Loading Data"""

# Load the Breast Cancer dataset
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"
column_names = ["Clump Thickness", "Uniformity of Cell Size", "Uniformity of Cell Shape",
                "Marginal Adhesion", "Single Epithelial Cell Size", "Bare Nuclei",
                "Bland Chromatin", "Normal Nucleoli", "Mitoses", "Class"]
data = pd.read_csv(url, names=column_names)

# Save the data as a CSV file
data.to_csv("breast_cancer_data.csv", index=False)

# Load data from csv
cell_df = pd.read_csv("breast_cancer_data.csv")
cell_df.tail()
cell_df.shape
cell_df.size
cell_df.count()
cell_df['Class'].value_counts

"""## Data PreProcessing"""

# Distribution of the classes
benign_df =cell_df[cell_df['Class']==2][0:200]
malignant_df =cell_df[cell_df['Class']==4][0:200]

#help(benign_df.plot)
axes = benign_df.plot(kind='scatter', x='Clump Thickness', y='Uniformity of Cell Size', color='blue', label='Benign')
malignant_df.plot(kind='scatter', x='Clump Thickness', y='Uniformity of Cell Size', color='red', label='Malignant', ax=axes)

"""# Identifying Unwanted Rows"""

cell_df.dtypes

# Drop unwanted rows with missing values and convert 'Bare Nuclei' to numeric
cell_df = cell_df[pd.to_numeric(cell_df['Bare Nuclei'], errors= 'coerce').notnull()]
cell_df['Bare Nuclei'] = cell_df['Bare Nuclei'].astype('int')
cell_df.dtypes

"""# Remove unwanted columns"""

# Select features and target variable
cell_df.columns
feature_df = cell_df[['Clump Thickness','Uniformity of Cell Size',
       'Uniformity of Cell Shape', 'Marginal Adhesion',
       'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',
       'Normal Nucleoli', 'Mitoses'] ]

# cell_df contains 100 rows and 11 columns , now i picked 9 columns out of 11
X = np.asarray(feature_df)               #............ Independent variable
y = np.asarray(cell_df['Class'])         #............. Dependent variable

y[0:5]

"""# Plotting characteristics for each class (benign and malignant)."""

# Create violin plot for characteristics
# Combine features and target variable into a single DataFrame
plot_data = pd.concat([feature_df, pd.Series(y, name='Class')], axis=1)

# Melt the DataFrame to long format for violin plot
melted_data = pd.melt(plot_data, id_vars='Class', var_name='Characteristic', value_name='Value')

# Create a violin plot
plt.figure(figsize=(16, 6))
sns.violinplot(x='Characteristic', y='Value', hue='Class', data=melted_data, split=True, inner="quart",palette = 'Set1')
plt.title('Violin Plot of Characteristics')
plt.xlabel('Characteristic')
plt.ylabel('Value')
plt.savefig("violin_plot_of_characteristics.png")
plt.show()

"""# Correlation between Variables"""

# Compute the correlation matrix
correlation_matrix = feature_df.corr()

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=.5)
plt.title('Correlation Matrix of Features')
plt.savefig("correlation_matrix.png")
plt.show()

"""# Split the data as Training and Testing sets"""

'''
cell_df(100)--> Train(80 rows) / Test (20 rows)
Train(X,y)  ## X itself is a 2D array, ## y is 1D
Test(X,y)
'''
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)

# 546 x 9
X_train.shape

# 546 x 1
y_train.shape

# 137 x 9
X_test.shape

# Check unique values in y_test
unique_labels = np.unique(y_test)
print("Unique labels in y_test:", unique_labels)

"""# Classsification Methods
# Modeling(SVM with Scikit-learn)
The SVM algorithm offers a choice of kernel functions for performing its processing.Basically, mapping data into a higher dimensional space is called kernelling.The mathematical function (kernel function) can be different types(linear,polynomial,RBF,sigmoid).Here I am using the linear function.
"""

svm_model = SVC(kernel='linear', gamma='auto', C=2)
svm_model.fit(X_train, y_train)
y_pred_svm = svm_model.predict(X_test)

# Evaluate the SVM model
svm_accuracy = accuracy_score(y_test, y_pred_svm)
svm_precision_per_class = precision_score(y_test, y_pred_svm, average=None)
svm_recall_per_class = recall_score(y_test, y_pred_svm, average=None)
svm_f1_per_class = f1_score(y_test, y_pred_svm, average=None)

"""## Evaluation of SVM"""

# Print metrics for each class
for label, precision, recall, f1 in zip(unique_labels, svm_precision_per_class, svm_recall_per_class, svm_f1_per_class):
    print(f"SVM - Label {label}: Precision={precision:.2f}, Recall={recall:.2f}, F1 Score={f1:.2f}")

# Print accuracy and report
print('SVM Accuracy:',svm_accuracy)
print(classification_report(y_test, y_pred_svm))

"""# Now, let's move on to Decision Trees and Random Forests

##  Compile the Models
"""

# Decision Tree Model
dt_model = DecisionTreeClassifier(random_state=4)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)

# Random  Forest Model
rf_model = RandomForestClassifier(random_state=4)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

"""# Evaluation of the Models"""

# Evaluate Decision Tree Model
dt_accuracy = accuracy_score(y_test, y_pred_dt)
dt_precision_per_class= precision_score(y_test, y_pred_dt, average=None)
dt_recall_per_class = recall_score(y_test, y_pred_dt, average=None)
dt_f1_per_class = f1_score(y_test, y_pred_dt, average=None)

# Evaluate Random Forest Model
rf_accuracy = accuracy_score(y_test, y_pred_rf)
rf_precision_per_class = precision_score(y_test, y_pred_rf, average = None)
rf_recall_per_class = recall_score(y_test, y_pred_rf, average = None)
rf_f1_per_class = f1_score(y_test, y_pred_rf, average = None)

"""# Results"""

# Print evaluation results for Decision Tree
print("Decision Tree Metrics:")
print("Accuracy:", dt_accuracy)
print(classification_report(y_test, y_pred_dt))

# Print evaluation results for Random Forest
print("Random Forest Metrics:")
print("Accuracy:", rf_accuracy)
print(classification_report(y_test, y_pred_rf))

# Metrics for SVM
svm_metrics = [svm_accuracy, np.mean(svm_precision_per_class), np.mean(svm_recall_per_class), np.mean(svm_f1_per_class)]

# Metrics for Decision Tree
dt_metrics = [dt_accuracy, np.mean(dt_precision_per_class), np.mean(dt_recall_per_class), np.mean(dt_f1_per_class)]

# Metrics for Random Forest
rf_metrics = [rf_accuracy, np.mean(rf_precision_per_class), np.mean(rf_recall_per_class), np.mean(rf_f1_per_class)]

models = ['SVM', 'Decision Tree', 'Random Forest']
metrics_data = np.array([svm_metrics, dt_metrics, rf_metrics])

fig, axs = plt.subplots(2, 2, figsize=(10, 8))
fig.suptitle('Model Comparison - Performance Metrics')

for i, metric in enumerate(['Accuracy', 'Precision', 'Recall', 'F1 Score']):
    row = i // 2
    col = i % 2
    axs[row, col].bar(models, metrics_data[:, i], color=['blue', 'green', 'orange'])
    axs[row, col].set_title(f'Model Comparison - {metric}')
    axs[row, col].set_ylabel(metric)
plt.savefig("model comparison-performance metrics.png")
  plt.show()
